{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e0eb4a",
   "metadata": {},
   "source": [
    "#### Тема «Создание признакового пространства»\n",
    "Продолжим обработку данных с Твиттера.\n",
    "1. Создайте мешок слов с помощью\n",
    "sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed'\n",
    "и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "● Игнорируем слова, частота которых в документе строго превышает порог 0.9 с\n",
    "помощью max_df.\n",
    "\n",
    "● Ограничим количество слов, попадающий в мешок, с помощью max_features =\n",
    "1000.\n",
    "\n",
    "● Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "● Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с\n",
    "помощью CountVectorizer.get_feature_names().\n",
    "\n",
    "2. Создайте мешок слов с помощью\n",
    "\n",
    "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и\n",
    "'tweet_lemmatized' отдельно.\n",
    "\n",
    "● Игнорируем слова, частота которых в документе строго превышает порог 0.9 с\n",
    "помощью max_df.\n",
    "\n",
    "● Ограничим количество слов, попадающий в мешок, с помощью max_features =\n",
    "1000.\n",
    "\n",
    "● Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "● Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с\n",
    "помощью TfidfVectorizer.get_feature_names().\n",
    "\n",
    "3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте\n",
    "таблицу метод векторизации и скор который вы получили (в методах векторизации по\n",
    "изменяйте параметры что бы добиться лучшего скора) обратите внимание как\n",
    "падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же\n",
    "попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на\n",
    "качество сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3857b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4acb847d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thank, lyft, credit, use, cause, offer, wheel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "3                      [model, love, take, time, ur]   \n",
       "4                        [factsguid, societi, motiv]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thank, lyft, credit, use, cause, offer, wheel...  \n",
       "2                                  [bihday, majesty]  \n",
       "3                      [model, love, take, time, ur]  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = pd.read_pickle('./combine_df.pkl')\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440232f",
   "metadata": {},
   "source": [
    "#### 1. Создайте мешок слов с помощью sklearn.feature_extraction.text.CountVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "● Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "\n",
    "● Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "\n",
    "● Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "● Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью CountVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2f21e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual  ad  adapt  ...  \\\n",
       "0    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "1    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "2    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "3    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "4    0        0       0        0    0       0      0       0   0      0  ...   \n",
       "\n",
       "   yeah  year  yesterday  yo  yoga  york  young  youtub  yr  yummi  \n",
       "0     0     0          0   0     0     0      0       0   0      0  \n",
       "1     0     0          0   0     0     0      0       0   0      0  \n",
       "2     0     0          0   0     0     0      0       0   0      0  \n",
       "3     0     0          0   0     0     0      0       0   0      0  \n",
       "4     0     0          0   0     0     0      0       0   0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer_stemmed = CountVectorizer(max_df=0.9, \n",
    "                                           max_features = 1000, \n",
    "                                           stop_words='english', \n",
    "                                           binary=False)\n",
    "\n",
    "bag_of_words_stemmed = count_vectorizer_stemmed.fit_transform(\n",
    "    combine_df.tweet_stemmed.apply(lambda x: ' '.join([word for word in x]))\n",
    ")\n",
    "\n",
    "feature_names = count_vectorizer_stemmed.get_feature_names()\n",
    "\n",
    "df_bag_of_words_stemmed = pd.DataFrame(bag_of_words_stemmed.toarray(), columns=feature_names)\n",
    "df_bag_of_words_stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbafc25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Columns: 1000 entries, abl to yummi\n",
      "dtypes: int64(1000)\n",
      "memory usage: 375.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_bag_of_words_stemmed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea418f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0     0           0       0        0    0       0      0         0      0   \n",
       "1     0           0       0        0    0       0      0         0      0   \n",
       "2     0           0       0        0    0       0      0         0      0   \n",
       "3     0           0       0        0    0       0      0         0      0   \n",
       "4     0           0       0        0    0       0      0         0      0   \n",
       "\n",
       "   add  ...  yesterday  yo  yoga  york  young  youth  youtube  yr  yrs  yummy  \n",
       "0    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "1    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "2    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "3    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "4    0  ...          0   0     0     0      0      0        0   0    0      0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer_lemmatized = CountVectorizer(max_df=0.9, \n",
    "                                             max_features = 1000, \n",
    "                                              stop_words='english', \n",
    "                                              binary=False)\n",
    "\n",
    "bag_of_words_lemmatized = count_vectorizer_lemmatized.fit_transform(\n",
    "    combine_df.tweet_lemmatized.apply(lambda x: ' '.join([word for word in x]))\n",
    ")\n",
    "\n",
    "feature_names = count_vectorizer_lemmatized.get_feature_names()\n",
    "\n",
    "df_bag_of_words_lemmatized = pd.DataFrame(bag_of_words_lemmatized.toarray(), columns=feature_names)\n",
    "df_bag_of_words_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16112556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Columns: 1000 entries, able to yummy\n",
      "dtypes: int64(1000)\n",
      "memory usage: 375.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_bag_of_words_lemmatized.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f41db9",
   "metadata": {},
   "source": [
    "#### 2. Создайте мешок слов с помощью sklearn.feature_extraction.text.TfidfVectorizer.fit_transform(). Применим его к 'tweet_stemmed' и 'tweet_lemmatized' отдельно.\n",
    "\n",
    "● Игнорируем слова, частота которых в документе строго превышает порог 0.9 с помощью max_df.\n",
    "\n",
    "● Ограничим количество слов, попадающий в мешок, с помощью max_features = 1000.\n",
    "\n",
    "● Исключим стоп-слова с помощью stop_words='english'.\n",
    "\n",
    "● Отобразим Bag-of-Words модель как DataFrame. columns необходимо извлечь с помощью TfidfVectorizer.get_feature_names()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d0b7c",
   "metadata": {},
   "source": [
    "##### tweet_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333abcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yummi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abl  absolut  accept  account  act  action  actor  actual   ad  adapt  ...  \\\n",
       "0  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "1  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "2  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "3  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "4  0.0      0.0     0.0      0.0  0.0     0.0    0.0     0.0  0.0    0.0  ...   \n",
       "\n",
       "   yeah  year  yesterday   yo  yoga  york  young  youtub   yr  yummi  \n",
       "0   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "1   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "2   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "3   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "4   0.0   0.0        0.0  0.0   0.0   0.0    0.0     0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_stemmed = TfidfVectorizer(max_df=0.9, \n",
    "                                           max_features = 1000, \n",
    "                                           stop_words='english')\n",
    "\n",
    "values_stemmed = tfidf_vectorizer_stemmed.fit_transform(\n",
    "    combine_df.tweet_stemmed.apply(lambda x: ' '.join([word for word in x]))\n",
    ")\n",
    "\n",
    "feature_names = tfidf_vectorizer_stemmed.get_feature_names()\n",
    "\n",
    "df_tfidf_vectorizer_stemmed = pd.DataFrame(values_stemmed.toarray(), columns = feature_names)\n",
    "df_tfidf_vectorizer_stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba96eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Columns: 1000 entries, abl to yummi\n",
      "dtypes: float64(1000)\n",
      "memory usage: 375.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_tfidf_vectorizer_stemmed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50395f6",
   "metadata": {},
   "source": [
    "##### tweet_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101f5dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actually</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accept  account  act  action  actor  actually  adapt  \\\n",
       "0   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "1   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "2   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "3   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "4   0.0         0.0     0.0      0.0  0.0     0.0    0.0       0.0    0.0   \n",
       "\n",
       "   add  ...  yesterday   yo  yoga  york  young  youth  youtube   yr  yrs  \\\n",
       "0  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "1  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "2  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "3  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "4  0.0  ...        0.0  0.0   0.0   0.0    0.0    0.0      0.0  0.0  0.0   \n",
       "\n",
       "   yummy  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_lemmatized = TfidfVectorizer(max_df=0.9, \n",
    "                                              max_features = 1000, \n",
    "                                              stop_words='english')\n",
    "\n",
    "values_lemmatized = tfidf_vectorizer_lemmatized.fit_transform(\n",
    "    combine_df.tweet_lemmatized.apply(lambda x: ' '.join([word for word in x]))\n",
    ")\n",
    "\n",
    "feature_names = tfidf_vectorizer_lemmatized.get_feature_names()\n",
    "\n",
    "df_tfidf_vectorizer_lemmatized = pd.DataFrame(values_lemmatized.toarray(), columns = feature_names)\n",
    "df_tfidf_vectorizer_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36404b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Columns: 1000 entries, able to yummy\n",
      "dtypes: float64(1000)\n",
      "memory usage: 375.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_tfidf_vectorizer_lemmatized.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26e75c",
   "metadata": {},
   "source": [
    "#### 3. Проверьте ваши векторайзеры на корпусе который использовали на вебинаре, составьте таблицу метод векторизации и скор который вы получили (в методах векторизации по изменяйте параметры что бы добиться лучшего скора) обратите внимание как падает/растёт скор при уменьшении количества фичей, и изменении параметров, так же попробуйте применить к векторайзерам PCA для сокращения размерности посмотрите на качество сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de41bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
       "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
       "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
       "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
       "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = open('./corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(corpus.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# создаем df\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e38e15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'],\n",
    "                                                                      trainDF['label'])\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc1ddbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_corp = CountVectorizer(analyzer='word', \n",
    "                                  token_pattern=r'\\w{1,}')\n",
    "\n",
    "tfidf_vec_corp = TfidfVectorizer(analyzer='word', \n",
    "                                 token_pattern=r'\\w{1,}')\n",
    "\n",
    "count_vect_corp_mod = CountVectorizer(max_df=0.9, \n",
    "                                      max_features = 1000, \n",
    "                                      stop_words='english', \n",
    "                                      analyzer='word', \n",
    "                                      token_pattern=r'\\w{1,}')\n",
    "\n",
    "tfidf_vec_corp_mod = TfidfVectorizer(max_df=0.9, \n",
    "                                     max_features = 1000, \n",
    "                                     stop_words='english', \n",
    "                                     analyzer='word', \n",
    "                                     token_pattern=r'\\w{1,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c06f96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, max_features=1000, stop_words='english',\n",
       "                token_pattern='\\\\w{1,}')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_corp.fit(trainDF['text'])\n",
    "tfidf_vec_corp.fit(trainDF['text'])\n",
    "count_vect_corp_mod.fit(trainDF['text'])\n",
    "tfidf_vec_corp_mod.fit(trainDF['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e50240",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "\n",
    "vectorizers = [count_vect_corp,\n",
    "               tfidf_vec_corp, \n",
    "                       \n",
    "               count_vect_corp_mod, \n",
    "               tfidf_vec_corp_mod, \n",
    "                       \n",
    "               count_vectorizer_stemmed, \n",
    "               tfidf_vectorizer_stemmed, \n",
    "                       \n",
    "               count_vectorizer_lemmatized, \n",
    "               tfidf_vectorizer_lemmatized]\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "\n",
    "    xtrain_count = vectorizer.transform(train_x)\n",
    "    xvalid_count = vectorizer.transform(valid_x)\n",
    "\n",
    "    classifier = linear_model.LogisticRegression()    \n",
    "    classifier.fit(xtrain_count, train_y)\n",
    "    \n",
    "    predictions = classifier.predict(xvalid_count)\n",
    "    \n",
    "    res = res.append(\n",
    "        pd.DataFrame([[str(vectorizer), accuracy_score(valid_y, predictions)]], columns=['Vectorizer', 'Score'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de57c936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer(token_pattern='\\\\w{1,}')</td>\n",
       "      <td>0.8664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(token_pattern='\\\\w{1,}')</td>\n",
       "      <td>0.8564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.8272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.8076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.7436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TfidfVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.7276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(max_df=0.9, max_features=1000,...</td>\n",
       "      <td>0.7160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Vectorizer   Score\n",
       "0           TfidfVectorizer(token_pattern='\\\\w{1,}')  0.8664\n",
       "0           CountVectorizer(token_pattern='\\\\w{1,}')  0.8564\n",
       "0  TfidfVectorizer(max_df=0.9, max_features=1000,...  0.8272\n",
       "0  CountVectorizer(max_df=0.9, max_features=1000,...  0.8076\n",
       "0  TfidfVectorizer(max_df=0.9, max_features=1000,...  0.7532\n",
       "0  CountVectorizer(max_df=0.9, max_features=1000,...  0.7436\n",
       "0  TfidfVectorizer(max_df=0.9, max_features=1000,...  0.7276\n",
       "0  CountVectorizer(max_df=0.9, max_features=1000,...  0.7160"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('Score', ascending=False, inplace=True)\n",
    "res.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b29d6",
   "metadata": {},
   "source": [
    "##### Вывод: \n",
    "Наилучший результат показал TfidfVectorizer с использованием token_pattern (0.8664). С уменьшением фичей результат ухудшается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac27d8",
   "metadata": {},
   "source": [
    "####  Применим PCA к векторайзерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b5f6b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 31681)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = tfidf_vec_corp.fit_transform(trainDF['text'])\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bb2416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Что-то тормозит, посмотрим как выполняется. Не зависло ли?\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021fd4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 6/6 [1:25:35<00:00, 855.87s/it]\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "\n",
    "for n_components in tqdm ([100, 300, 500, 1000, 3000, 5000]):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    \n",
    "    xtrain_count =  count_vect_corp.transform(train_x)\n",
    "    xvalid_count =  count_vect_corp.transform(valid_x)\n",
    "\n",
    "    xtrain_count_pca =  svd.fit_transform(xtrain_count)\n",
    "    xvalid_count_pca =  svd.transform(xvalid_count)\n",
    "\n",
    "    classifier = linear_model.LogisticRegression()\n",
    "    classifier.fit(xtrain_count_pca, train_y)\n",
    "    \n",
    "    predictions = classifier.predict(xvalid_count_pca)\n",
    "    \n",
    "    res = res.append(\n",
    "        pd.DataFrame([[str(n_components), accuracy_score(valid_y, predictions)]], columns=['# Components', 'Score'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e045ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Components</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.7728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.8356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.8436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>0.8516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Components   Score\n",
       "0          100  0.7728\n",
       "0          300  0.8356\n",
       "0          500  0.8436\n",
       "0         5000  0.8516\n",
       "0         1000  0.8520\n",
       "0         3000  0.8532"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('Score', ascending=True, inplace=True)\n",
    "res.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5dcf3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res['# Components'], res['Score']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf532a",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "1. При сокращении размерности PCA качество модели уменьшается. Хотя есть исключения, например при увеличении фичей до 5000 точность предсказаний уменьшилась по сравнению с 3000.\n",
    "2. Увеличение признаков резко приводит к замедлению скорости работы модели. Так при значении n_components = 100, модель отработала примерно за 30 сек, при 5000 за 1:25:35.\n",
    "3. Принимая во внимания пп 1 и 2, можно сделать вывод что существует некое оптимальное количество признаков для каждой модели и оно не всегда является максимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c175b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
