{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача поиск похожих по эмбеддингам\n",
    "\n",
    "Скачиваем датасет ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv).\n",
    "\n",
    "или можно через ноутбук\n",
    "\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
    "\n",
    "что надо сделать \n",
    "1. объединить в одну выборку\n",
    "2. на основе word2vec/fasttext/glove/слоя Embedding реализовать метод поиска ближайших твитов\n",
    "\n",
    "на вход метода должен приходить запрос (какой-то твит, вопрос) и количество вариантов вывода к примеру 5-ть, ваш метод должен возвращать 5-ть ближайших твитов к этому запросу.\n",
    "\n",
    "3. Проверить насколько хорошо работают подходы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "# from tqdm import tqdm_notebook\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Объеденяем 2 датасета в 1 выборку и делаем легкую предобработку текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226834 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       @first_timee хоть я и школота, но поверь, у на...\n",
       "1       Да, все-таки он немного похож на него. Но мой ...\n",
       "2       RT @KatiaCheh: Ну ты идиотка) я испугалась за ...\n",
       "3       RT @digger2912: \"Кто то в углу сидит и погибае...\n",
       "4       @irina_dyshkant Вот что значит страшилка :D\\nН...\n",
       "...                                                   ...\n",
       "111918  Но не каждый хочет что то исправлять:( http://...\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...\n",
       "111920          Вот и в школу, в говно это идти уже надо(\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...\n",
       "\n",
       "[226834 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "df = positive.append(negative)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     хоть я и школота, но поверь, у нас то же само...\n",
       "1    Да, все-таки он немного похож на него. Но мой ...\n",
       "2          RT : Ну ты идиотка) я испугалась за тебя!!!\n",
       "3    RT : \"Кто то в углу сидит и погибает от голода...\n",
       "4     Вот что значит страшилка :D\\nНо блин,посмотре...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user_delete_re_sub (pattern, repl, string):\n",
    "    return re.sub(pattern, repl, string)\n",
    "\n",
    "df.text = np.vectorize(user_delete_re_sub)('@[\\w]*', '', df.text)\n",
    "df.text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хоть я и школота, но поверь, у нас то же само...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT : Ну ты идиотка) я испугалась за тебя!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT : \"Кто то в углу сидит и погибает от голода...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вот что значит страшилка :D\\nНо блин,посмотре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только  вправляет мозги, но я в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT :  Тауриэль, не грусти :( *обнял*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226834 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0        хоть я и школота, но поверь, у нас то же само...\n",
       "1       Да, все-таки он немного похож на него. Но мой ...\n",
       "2             RT : Ну ты идиотка) я испугалась за тебя!!!\n",
       "3       RT : \"Кто то в углу сидит и погибает от голода...\n",
       "4        Вот что значит страшилка :D\\nНо блин,посмотре...\n",
       "...                                                   ...\n",
       "111918  Но не каждый хочет что то исправлять:( http://...\n",
       "111919  скучаю так :-( только  вправляет мозги, но я в...\n",
       "111920          Вот и в школу, в говно это идти уже надо(\n",
       "111921               RT :  Тауриэль, не грусти :( *обнял*\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...\n",
       "\n",
       "[226834 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].apply(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"text_in.txt\", header=None, index=None, sep=',', mode='w', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_in = open('text_in.txt','r', encoding='utf-8')\n",
    "# print(*text_in) # текст очень большой для github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На основе word2vec/fasttext слоя Embedding реализоваваем метод поиска ближайших твитов (glove не установился)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.info()['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7699\n"
     ]
    }
   ],
   "source": [
    "# загрузим предтренированные вектора и проверим работоспособность\n",
    "\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # загрузим предтренированные вектора слов из gensim-data\n",
    "# выведим слово наиболее близкое к 'woman', 'king' и далекое от 'man'\n",
    "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(\"{}: {:.4f}\".format(*result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323495\n",
      "0.5288512\n",
      "0.21199903\n"
     ]
    }
   ],
   "source": [
    "# определим схожесть между словами\n",
    "similarity = word_vectors.similarity('woman', 'man')\n",
    "print(similarity)\n",
    "\n",
    "similarity = word_vectors.similarity('human', 'man')\n",
    "print(similarity)\n",
    "\n",
    "similarity = word_vectors.similarity('bee', 'man')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.832349419593811), ('boy', 0.7914870977401733), ('one', 0.7788748741149902)]\n",
      "[('dog', 0.8798074722290039), ('rabbit', 0.7424426674842834), ('cats', 0.7323004007339478)]\n",
      "[('tongue', 0.7366125583648682), ('mouths', 0.687748908996582), ('ear', 0.6811771988868713)]\n"
     ]
    }
   ],
   "source": [
    "# найдем top-3 самых близких слов\n",
    "result = word_vectors.similar_by_word(\"man\", topn=3)\n",
    "print(result)\n",
    "\n",
    "result = word_vectors.similar_by_word(\"cat\", topn=3)\n",
    "print(result)\n",
    "\n",
    "result = word_vectors.similar_by_word(\"mouth\", topn=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57393185c2824ba381c186a4e876c5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "#Small preprocess of the answers\n",
    "\n",
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(\"prepared_text.txt\", \"w\") as fout:\n",
    "    with open(\"text_in.txt\", \"r\", encoding='utf-8') as fin:\n",
    "        for line in notebook.tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bf16aa01a4467da3caef82d22ed1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert True\n",
    "\n",
    "# Preprocess for models fitting\n",
    "\n",
    "sentences = []\n",
    "\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "c = 0\n",
    "\n",
    "with open(\"text_in.txt\", \"r\", encoding='utf-8') as fin:\n",
    "    for line in notebook.tqdm(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        c += 1\n",
    "        if c > 100000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [i for i in sentences if len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['школотый',\n",
       " 'поверь',\n",
       " 'самый',\n",
       " 'd',\n",
       " 'общество',\n",
       " 'профилировать',\n",
       " 'предмет',\n",
       " 'тип']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=sentences, size=300, window=5, min_count=1)\n",
    "modelFT = FastText(sentences=sentences, size=300, min_count=1, window=5, workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cfbc3c1fd24bec84a167c60668fa62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "ft_index = annoy.AnnoyIndex(300 ,'angular')\n",
    "\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(\"prepared_text.txt\", \"r\") as f:\n",
    "    for line in notebook.tqdm(f):\n",
    "        n_w2v = 0\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = spls[1]\n",
    "        question = preprocess_txt(spls[0])\n",
    "        \n",
    "        vector_w2v = np.zeros(300)\n",
    "        vector_ft = np.zeros(300)\n",
    "        for word in question:\n",
    "            if word in modelW2V.wv:\n",
    "                vector_w2v += modelW2V.wv[word]\n",
    "                n_w2v += 1\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_w2v > 0:\n",
    "            vector_w2v = vector_w2v / n_w2v\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        w2v_index.add_item(counter, vector_w2v)\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "            \n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 100000:\n",
    "            break\n",
    "\n",
    "w2v_index.build(10)\n",
    "ft_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question, index, model, index_map):\n",
    "    question = preprocess_txt(question)\n",
    "    vector = np.zeros(300)\n",
    "    norm = 0\n",
    "    for word in question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "    answers = index.get_nns_by_vector(vector, 5, ) # возвращаем 5 ближайших вектора \n",
    "    return [index_map[i] for i in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"хоть я и школота, но поверь, у нас то же самое общество профилирующий предмет типа\" # берём самый первый твит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\"\\n',\n",
       " '\"Надеялась, что я добавлю ее в друзья,лохушка :D http://t.co/36k6ADyASA\"\\n',\n",
       " '\"с утра романтик, засевший глубоко среди извилин мозга, получил суровым кирпичом действительности по голове) и вас с добры\"\\n',\n",
       " '\"Кто круче - 1,2,3,4 ?) #Suri http://t.co/jZ0INfN4tx\"\\n',\n",
       " '\"И вот я сижу .. А он передо мной ..в трусах , а я засыпаю :D\"\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, w2v_index, modelW2V, index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\"\\n',\n",
       " '\"RT : По телеку показывали \"\"Квартал-95\"\". Они пригласили Чайф! =)) Наконец-то догадались, что Киркоров и Моисеев не нужны. Вообщ\"\\n',\n",
       " '\"Надеялась, что я добавлю ее в друзья,лохушка :D http://t.co/36k6ADyASA\"\\n',\n",
       " '\"Кто круче - 1,2,3,4 ?) #Suri http://t.co/jZ0INfN4tx\"\\n',\n",
       " '\"И вот я сижу .. А он передо мной ..в трусах , а я засыпаю :D\"\\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(TEXT, ft_index, modelFT, index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "- Подходы работают относительно неплохо, особенно первые ответы (в запросе есть \"то же самое\", а первые ответы соджержат \"похож\")\n",
    "- Последующие ответы оставляют желать лучшего, хотя определённая логика прослеживается. Например, \"школота\" - \"лохушка\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
